name: Fedlin Azure Secure CI/CD (Self-Contained)

on:
  push:
    branches: [ "main" ]
    paths:
      - ".github/workflows/deploy-azure.yml"
  workflow_dispatch:
    inputs:
      subscription_id:
        description: "Azure Subscription ID"
        required: true
      tenant_id:
        description: "Azure Tenant ID"
        required: true
      client_id:
        description: "Entra App (GitHub OIDC) Client ID"
        required: true
      ssh_cidr:
        description: "CIDR(s) allowed for SSH this run (e.g., 203.0.113.4/32 or '203.0.113.4/32 198.51.100.7/32')"
        required: false
        default: ""


permissions:
  id-token: write    # OIDC to Azure
  contents: write

concurrency:
  group: fedlin-azure-secure-cicd
  cancel-in-progress: false

env:
  # ---- Portfolio-friendly defaults (override as needed) ----
  REGION: eastus
  RESOURCE_PREFIX: fedlin
  VM_SIZE: Standard_B1s          # free/low-cost tier friendly
  SSH_USERNAME: "fedlin"
  MY_IP: "*"                     # tighten to your /32 later (e.g., "X.Y.Z.W/32")
  ENABLE_HTTP: "false"           # "true" opens 80/443 in NSG
  IMAGE_URN: almalinux:almalinux:9-gen2:latest
  VNET_CIDR: 10.10.0.0/16
  SUBNET_CIDR: 10.10.1.0/24

jobs:
  deploy:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Azure Login (OIDC)
        uses: azure/login@v2
        with:
          client-id: ${{ inputs.client_id }}
          tenant-id: ${{ inputs.tenant_id }}
          subscription-id: ${{ inputs.subscription_id }}

      - name: Preflight checks
        env:
          SSH_PUBLIC_KEY: "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHSAmyIPFw2Ms25cOb2xhCw7liSrmVn9vUAUUCTPIfEZ github-anthracite-iv"
        run: |
          set -euo pipefail
          echo "==> Preflight: SSH public key"
          if [[ -z "${SSH_PUBLIC_KEY:-}" ]]; then
            echo "ERROR: SSH_PUBLIC_KEY secret missing. Set it in Settings → Secrets and variables → Actions." >&2
            exit 1
          fi
          SSH_PUBLIC_KEY="$(echo -n "$SSH_PUBLIC_KEY" | tr -d '\r')"
          echo "::add-mask::$SSH_PUBLIC_KEY"
          echo "OK: Public key detected (type: ${SSH_PUBLIC_KEY%% *})"

      - name: Deploy Azure resources (VNET, NSG, VM, LAW, DCR, AMA)
        env:
          REGION: ${{ env.REGION }}
          RESOURCE_PREFIX: ${{ env.RESOURCE_PREFIX }}
          VM_SIZE: ${{ env.VM_SIZE }}
          SSH_USERNAME: "fedlin"
          SSH_PUBLIC_KEY: "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHSAmyIPFw2Ms25cOb2xhCw7liSrmVn9vUAUUCTPIfEZ github-anthracite-iv"
          MY_IP: ${{ inputs.ssh_cidr || secrets.MY_IP || vars.MY_IP || '' }}
          ENABLE_HTTP: ${{ env.ENABLE_HTTP }}
          VNET_CIDR: ${{ env.VNET_CIDR }}
          SUBNET_CIDR: ${{ env.SUBNET_CIDR }}
          OPEN_SSH: ${{ inputs.open_ssh || 'false' }}
        run: |
          set -euo pipefail
          # Ensure an SSH public key is available for VM creation
          mkdir -p outputs
          if [[ -z "${SSH_PUBLIC_KEY:-}" ]]; then
            echo "No SSH_PUBLIC_KEY secret found; generating a temporary keypair..."
            mkdir -p .tmp_ssh
            ssh-keygen -t ed25519 -N "" -f .tmp_ssh/id_ed25519 -C "Fedlin"
            SSH_PUBLIC_KEY="$(cat .tmp_ssh/id_ed25519.pub)"
            tar -czf outputs/temp_ssh_keypair.tgz -C .tmp_ssh id_ed25519 id_ed25519.pub
          fi
          printf '%s\n' "$SSH_PUBLIC_KEY" > .tmp_pubkey
          echo "Using SSH key fingerprint: $(ssh-keygen -lf .tmp_pubkey | awk '{print $2}')"

          RG="${RESOURCE_PREFIX}-rg"
          LAW="${RESOURCE_PREFIX}-law"
          DCR="${RESOURCE_PREFIX}-dcr"
          DCRA="${RESOURCE_PREFIX}-dcra"
          VNET="${RESOURCE_PREFIX}-vnet"
          SUBNET="${RESOURCE_PREFIX}-subnet"
          NSG="${RESOURCE_PREFIX}-nsg"
          PIP="${RESOURCE_PREFIX}-pip"
          NIC="${RESOURCE_PREFIX}-nic"
          VM="${RESOURCE_PREFIX}-vm"
          AMA_NAME="AzureMonitorLinuxAgent"

          echo "==> Ensure Resource Group"
          az group show -n "$RG" >/dev/null 2>&1 || az group create -n "$RG" -l "$REGION" 1>/dev/null

          echo "==> Ensure Log Analytics Workspace"
          if ! LAW_ID="$(az monitor log-analytics workspace show -g "$RG" -n "$LAW" --query id -o tsv 2>/dev/null)"; then
            az monitor log-analytics workspace create -g "$RG" -n "$LAW" -l "$REGION" -o json > outputs/law_create.json
            LAW_ID="$(az monitor log-analytics workspace show -g "$RG" -n "$LAW" --query id -o tsv)"
          else
            az monitor log-analytics workspace show -g "$RG" -n "$LAW" -o json > outputs/law_show.json
          fi
          echo "LAW_ID=$LAW_ID"

          echo "==> Ensure Data Collection Rule (syslog → LAW)"
          DCR_FILE="$(mktemp)"
          cat > "$DCR_FILE" <<EOF
          {
            "location": "${REGION}",
            "properties": {
              "dataSources": {
                "syslog": [
                  {
                    "name": "syslog-source",
                    "streams": [ "Microsoft-Syslog" ],
                    "facilityNames": ["auth","authpriv","daemon","kern","syslog","user","local0"],
                    "logLevels": ["Debug","Info","Notice","Warning","Error","Critical","Alert","Emergency"]
                  }
                ]
              },
              "destinations": {
                "logAnalytics": [
                  {
                    "name": "law-dest",
                    "workspaceResourceId": "${LAW_ID}"
                  }
                ]
              },
              "dataFlows": [
                { "streams": ["Microsoft-Syslog"], "destinations": ["law-dest"] }
              ]
            }
          }
          EOF

          if ! az monitor data-collection rule show -g "$RG" -n "$DCR" 1>/dev/null 2>&1; then
            az monitor data-collection rule create -g "$RG" -n "$DCR" --rule-file "$DCR_FILE" -o json > outputs/dcr_create.json
          else
            echo "DCR exists; leaving as-is." | tee outputs/dcr_exists.txt
          fi
          DCR_ID="$(az monitor data-collection rule show -g "$RG" -n "$DCR" --query id -o tsv)"

          echo "==> Ensure VNET + Subnet"
          if ! az network vnet show -g "$RG" -n "$VNET" 1>/dev/null 2>&1; then
            az network vnet create -g "$RG" -n "$VNET" --address-prefix "$VNET_CIDR" \
              --subnet-name "$SUBNET" --subnet-prefix "$SUBNET_CIDR" -o json > outputs/vnet_create.json
          fi

          echo "==> Ensure NSG (attach; default rules only)"

          # Find the NIC on the VM
          NIC_ID="$(az vm show -g "$RG" -n "$VM" --query 'networkProfile.networkInterfaces[0].id' -o tsv)"

          # Ensure NSG exists
          if ! az network nsg show -g "$RG" -n "$NSG" >/dev/null 2>&1; then
            az network nsg create -g "$RG" -n "$NSG" -o json > outputs/nsg_create.json
          fi

          # Attach NSG to NIC if not already attached (idempotent)
          CUR_NSG_ID="$(az network nic show --ids "$NIC_ID" --query 'networkSecurityGroup.id' -o tsv || true)"
          if [[ -z "${CUR_NSG_ID:-}" || "${CUR_NSG_ID##*/}" != "$NSG" ]]; then
            az network nic update --ids "$NIC_ID" --network-security-group "$NSG" >/dev/null
          fi

          # Remove any custom rules so only Azure defaults remain (clean baseline)
          for RULE in Allow-SSH Allow-HTTP Allow-HTTPS; do
            az network nsg rule delete -g "$RG" --nsg-name "$NSG" -n "$RULE" >/dev/null 2>&1 || true
          done

          # Evidence: capture current rules table (will show defaults only)
          az network nsg rule list -g "$RG" --nsg-name "$NSG" -o table | tee outputs/nsg_rules.txt


          # Fallback Alma 9 Gen2 image if resolver finds nothing (no ':latest')
          : "${IMAGE_URN:=almalinux:almalinux-x86_64:9-gen2:9.6.202505220}"

          # Resolve exact AlmaLinux 9 Gen2 image for this region
          echo "Resolving AlmaLinux 9 Gen2 in ${REGION}..."
          ALMA_URN="$(az vm image list \
            --location "${REGION}" \
            --publisher almalinux \
            --offer almalinux \
            --sku 9-gen2 \
            --all \
            --query "sort_by(@, &version)[-1].urn" -o tsv || true)"
          if [[ -n "${ALMA_URN:-}" ]]; then
            IMAGE_URN="${ALMA_URN}"
          fi
          echo "Using IMAGE_URN=${IMAGE_URN}"

          # Prepare cloud-init early (set -u safe)
          CLOUD_INIT="$(mktemp)"
          echo "CLOUD_INIT at: $CLOUD_INIT"
          echo "==> Cloud-init hardening (EL9)"
          cat > "$CLOUD_INIT" <<EOF
          #cloud-config
          ssh_pwauth: false
          users:
            - name: "fedlin"
              sudo: ALL=(ALL) NOPASSWD:ALL
              groups: [ wheel ]
              shell: /bin/bash
              ssh_authorized_keys:
                - ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIHSAmyIPFw2Ms25cOb2xhCw7liSrmVn9vUAUUCTPIfEZ Fedlin

          package_update: true
          packages:
            - audit
            - policycoreutils-python-utils

          runcmd:
            - systemctl enable --now auditd
            - sed -i 's/^#\?ClientAliveInterval.*/ClientAliveInterval 300/' /etc/ssh/sshd_config
            - sed -i 's/^#\?ClientAliveCountMax.*/ClientAliveCountMax 2/' /etc/ssh/sshd_config
            - sed -i 's/^#\?LogLevel.*/LogLevel VERBOSE/' /etc/ssh/sshd_config
            - restorecon -Rv /home/fedlin || true
            - systemctl restart sshd
          EOF

          echo "==> Ensure VM (AlmaLinux 9)"
          if ! az vm show -g "$RG" -n "$VM" >/dev/null 2>&1; then
            az vm create \
              -g "$RG" -n "$VM" \
              --image "${IMAGE_URN}" \
              --size "$VM_SIZE" \
              --admin-username "$SSH_USERNAME" \
              --authentication-type ssh \
              --ssh-key-values "$SSH_PUBLIC_KEY" \
              --nics "$NIC" \
              --custom-data "$CLOUD_INIT" \
              --os-disk-name "${RESOURCE_PREFIX}-osdisk" \
              --public-ip-address "$PIP" \
              -o json > outputs/vm_create.json
              
          else
            az vm show -g "$RG" -n "$VM" -o json > outputs/vm_show.json
          fi

          PUBLIC_IP="$(az network public-ip show -g "$RG" -n "$PIP" --query ipAddress -o tsv)"
          printf '{"publicIp":"%s"}\n' "$PUBLIC_IP" > outputs/public_ip.json

          echo "==> Ensure Azure Monitor Agent (AMA) + DCR Association"
          if ! az vm extension show -g "$RG" --vm-name "$VM" --name "$AMA_NAME" \
               --query provisioningState -o tsv 2>/dev/null; then
            az vm extension set \
              -g "$RG" \
              --vm-name "$VM" \
              --publisher Microsoft.Azure.Monitor \
              --name "$AMA_NAME" \
              -o json > outputs/ama_install.json
          fi

          VM_ID="$(az vm show -g "$RG" -n "$VM" --query id -o tsv)"
          if ! az monitor data-collection rule association show \
                 --association-name "$DCRA" \
                 --resource "$VM_ID" >/dev/null 2>&1; then
            az monitor data-collection rule association create \
              --association-name "$DCRA" \
              --resource "$VM_ID" \
              --rule-id "$DCR_ID" \
              -o json > outputs/dcra_create.json
          fi

          echo "==> Capture evidence"
          az resource list -g "$RG" -o table | tee outputs/resources_table.txt
          az network nsg rule list -g "$RG" --nsg-name "$NSG" -o table | tee outputs/nsg_rules.txt

          cat > outputs/ssh_instructions.txt <<TXT
          SSH:
            ssh ${SSH_USERNAME}@${PUBLIC_IP}

          Notes:
            - Restrict SSH to your /32 by setting env.MY_IP (e.g., "1.2.3.4/32").
            - Set ENABLE_HTTP=true to allow TCP 80/443.
            - AMA installed; syslog flows to LAW via DCR "${DCR}".
          TXT

      - name: Collect & sanitize evidence (portfolio pack)
        if: ${{ success() }}
        run: |
          set -euo pipefail
          # re-derive names for this step (set -u safe)
          : "${RESOURCE_PREFIX:?RESOURCE_PREFIX must be set}"
          RG="${RESOURCE_PREFIX}-rg"
          LAW="${RESOURCE_PREFIX}-law"
          DCR="${RESOURCE_PREFIX}-dcr"
          NSG="${RESOURCE_PREFIX}-nsg"
          VM="${RESOURCE_PREFIX}-vm"

          mkdir -p evidence/raw evidence/safe

          echo "==> Gather raw evidence"
          az resource list -g "$RG" -o json > evidence/raw/resources.json
          az network nsg rule list -g "$RG" --nsg-name "$NSG" -o json > evidence/raw/nsg_rules.json
          az vm show -g "$RG" -n "$VM" -o json > evidence/raw/vm.json
          az monitor log-analytics workspace show -g "$RG" -n "$LAW" -o json > evidence/raw/law.json || true
          az monitor data-collection rule show -g "$RG" -n "$DCR" -o json > evidence/raw/dcr.json || true
          az monitor data-collection rule association list \
            --resource "$(az vm show -g "$RG" -n "$VM" --query id -o tsv)" -o json \
            > evidence/raw/dcra.json || true

          echo "==> Create human readable tables"
          az resource list -g "$RG" -o table > evidence/raw/resources_table.txt
          az network nsg rule list -g "$RG" --nsg-name "$NSG" -o table > evidence/raw/nsg_rules_table.txt

          echo "==> Redact sensitive values"
          redact() {
            sed -E \
              -e 's@/subscriptions/[^/"]+@/subscriptions/SUBSCRIPTION_REDACTED@g' \
              -e 's/[0-9]{1,3}(\.[0-9]{1,3}){3}/IP_REDACTED/g' \
              -e 's/"tenant(Id)?": *"[^"]+"/"tenant":"REDACTED"/g' \
              -e 's/"clientId": *"[^"]+"/"clientId":"REDACTED"/g'
          }
          for f in evidence/raw/*; do
            bn="$(basename "$f")"
            redact < "$f" > "evidence/safe/$bn" || cp "$f" "evidence/safe/$bn"
          done

          echo "==> Add short summary"
          {
            echo "# Evidence Summary"
            echo
            echo "## VM"
            jq -r '
              {name,location} + {size:.hardwareProfile.vmSize} +
              {image: ((.storageProfile.imageReference.publisher // "") + ":" +
                       (.storageProfile.imageReference.offer // "") + ":" +
                       (.storageProfile.imageReference.sku // ""))}
            ' evidence/safe/vm.json 2>/dev/null || true
            echo
            echo "## NSG rules (first 20)"
            head -n 20 evidence/raw/nsg_rules_table.txt 2>/dev/null || true
          } > evidence/safe/README-summary.md

      - name: Write outputs summary
        if: ${{ success() }}
        run: |
          mkdir -p project0-outputs
          cat > project0-outputs/outputs.json <<JSON
          {
            "subscriptionId": "${{ inputs.subscription_id }}",
            "tenantId": "${{ inputs.tenant_id }}",
            "clientId": "${{ inputs.client_id }}",
            "resourceGroup": "${{ env.RESOURCE_PREFIX }}-rg",
            "workspaceName": "${{ env.RESOURCE_PREFIX }}-law",
            "location": "${{ env.REGION }}"
          }
          JSON
          echo "✅ Wrote project0-outputs/outputs.json"

      - name: Commit Project 0 outputs.json
        if: ${{ success() }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -euo pipefail
          git config user.name "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git add project0-outputs/outputs.json
          # Commit only if there are changes
          if ! git diff --cached --quiet; then
            git commit -m "chore(project0): export outputs.json [skip ci]"
            # Push back to the same branch this workflow ran on
            git push origin "${GITHUB_REF#refs/heads/}"
            echo "✅ Pushed project0-outputs/outputs.json"
          else
            echo "ℹ️ No changes to outputs.json; nothing to commit."
          fi


      - name: Upload Evidence Pack (sanitized)
        if: ${{ success() }}
        uses: actions/upload-artifact@v4
        with:
          name: fedlin-evidence-pack
          path: evidence/safe
          if-no-files-found: warn
          retention-days: 7


      - name: Gate: Mirror to GitLab (secrets present?)
        id: mirror_gate
        if: ${{ always() }}
        shell: bash
        run: |
          set -euo pipefail
          if [[ -z "${{ secrets.GITLAB_TOKEN }}" || -z "${{ secrets.GITLAB_MIRROR_URL }}" ]]; then
            echo "run=no" >> "$GITHUB_OUTPUT"
            echo "ℹ️ GitLab mirroring skipped: missing GITLAB_TOKEN or GITLAB_MIRROR_URL."
          else
            echo "run=yes" >> "$GITHUB_OUTPUT"
          fi

      - name: Mirror to GitLab (branches + tags, 60s)
        if: steps.mirror_gate.outputs.run == 'yes'
        continue-on-error: true
        env:
          GITLAB_TOKEN: ${{ secrets.GITLAB_TOKEN }}
          GITLAB_MIRROR_URL: ${{ secrets.GITLAB_MIRROR_URL }} # https://oauth2:${GITLAB_TOKEN}@gitlab.com/<namespace>/<repo>.git
        shell: bash
        run: |
          set -euo pipefail
          echo "::add-mask::${GITLAB_TOKEN}"
          echo "::add-mask::${GITLAB_MIRROR_URL}"

          git config --global safe.directory "$GITHUB_WORKSPACE"
          git config user.name  "github-actions[bot]"
          git config user.email "41898282+github-actions[bot]@users.noreply.github.com"

          # Ensure full history/tags even if checkout used fetch-depth: 1
          git fetch --tags --force --prune
          if git rev-parse --is-shallow-repository >/dev/null 2>&1; then
            git fetch --unshallow || true
          fi

          # Add remote without echoing URL
          git remote remove gitlab 2>/dev/null || true
          git remote add gitlab "${GITLAB_MIRROR_URL}"

          # Push branches & tags with a hard 60s cap
          timeout 60s bash -lc '
            set -euo pipefail
            git push --prune gitlab --all
            git push gitlab --tags
          '

      - name: Mirror to GitLab skipped (no secrets)
        if: steps.mirror_gate.outputs.run != 'yes'
        shell: bash
        run: echo "Mirror step skipped; secrets not configured (expected for forks/local runs)."
